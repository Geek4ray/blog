<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>A Miniature Implementation of GPT Model | Welcome to Rayan’s Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="A Miniature Implementation of GPT Model" />
<meta name="author" content="Group-23" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This blog explains a minimalistic implementation of GPT Model on the basis of an Addition Problem." />
<meta property="og:description" content="This blog explains a minimalistic implementation of GPT Model on the basis of an Addition Problem." />
<link rel="canonical" href="https://geek4ray.github.io/blog/gpt/transformers/2021/11/22/Implementing-Miniature-GPT-Model.html" />
<meta property="og:url" content="https://geek4ray.github.io/blog/gpt/transformers/2021/11/22/Implementing-Miniature-GPT-Model.html" />
<meta property="og:site_name" content="Welcome to Rayan’s Blog" />
<meta property="og:image" content="https://geek4ray.github.io/blog/images/diagram.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-22T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://geek4ray.github.io/blog/gpt/transformers/2021/11/22/Implementing-Miniature-GPT-Model.html","@type":"BlogPosting","headline":"A Miniature Implementation of GPT Model","dateModified":"2021-11-22T00:00:00-06:00","datePublished":"2021-11-22T00:00:00-06:00","image":"https://geek4ray.github.io/blog/images/diagram.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://geek4ray.github.io/blog/gpt/transformers/2021/11/22/Implementing-Miniature-GPT-Model.html"},"author":{"@type":"Person","name":"Group-23"},"description":"This blog explains a minimalistic implementation of GPT Model on the basis of an Addition Problem.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://geek4ray.github.io/blog/feed.xml" title="Welcome to Rayan's Blog" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Welcome to Rayan&#39;s Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">A Miniature Implementation of GPT Model</h1><p class="page-description">This blog explains a minimalistic implementation of GPT Model on the basis of an Addition Problem.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-11-22T00:00:00-06:00" itemprop="datePublished">
        Nov 22, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Group-23</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      23 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#GPT">GPT</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#transformers">transformers</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/Geek4ray/blog/tree/master/_notebooks/2021-11-22-Implementing-Miniature-GPT-Model.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/Geek4ray/blog/master?filepath=_notebooks%2F2021-11-22-Implementing-Miniature-GPT-Model.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/Geek4ray/blog/blob/master/_notebooks/2021-11-22-Implementing-Miniature-GPT-Model.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-11-22-Implementing-Miniature-GPT-Model.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is Group-23 NLP Project : A Miniature Implemantation of GPT Model</p>
<p>Group Members :</p>
<ol>
<li>Mallikarjuna Naik - IEC2018029</li>
<li>Rakamal Gupta - IEC2018050</li>
<li>Rayan Kejriwal - IEC2018080</li>
<li>Muasim Wani - IEC2018085</li>
<li>Pavan Kalyan - IEC2018088</li>
</ol>
<p>under Prof. Muneendra Ojha, 
Dept. of IT, IIIT Allahabad, Prayagraj, India,</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p><code>Objective :"To Train a GPT model on a dedicated addition dataset to see if a Transformer can learn to add."</code>
Our Objective is inspired by the addition section in the GPT-3 paper (Language Models are a few shot learners)- <a href="https://arxiv.org/pdf/2005.14165v4.pdf">https://arxiv.org/pdf/2005.14165v4.pdf</a></p>
</blockquote>
<p>Code References Used :</p>
<ol>
<li><a href="https://github.com/openai/gpt-2">https://github.com/openai/gpt-2</a> - This has GPT code (only model code is taken but not training) in Tensorflow, which is converted to our usecase in PyTorch here.</li>
<li>Image GPT by OpenAI - <a href="https://github.com/openai/image-gpt">https://github.com/openai/image-gpt</a> </li>
<li>"Attention is all you need paper" - <a href="https://arxiv.org/pdf/1706.03762.pdf">https://arxiv.org/pdf/1706.03762.pdf</a></li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>&gt; Note: We advice to enable GPU before running this notebook on GoogleColab.</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Imports">1. Imports<a class="anchor-link" href="#1.-Imports"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">LambdaLR</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.dataloader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Setting-Our-Seed">2. Setting Our Seed<a class="anchor-link" href="#2.-Setting-Our-Seed"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Making deterministic, setting our seed</span>
<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Generating-Our-Datasets:">3. Generating Our Datasets:<a class="anchor-link" href="#3.-Generating-Our-Datasets:"> </a></h2><p>In order to generate training and validation data, we define our custom Addition Dataset Class. &lt;/br&gt;
&lt;/n&gt;
The sum of two n-digit numbers gives a third up to (n+1)-digit number. So our
encoding will simply be the n-digit first number, n-digit second number, 
and (n+1)-digit result, all simply concatenated together. Because each addition
problem is so structured, there is no need to bother the model with encoding
+, =, or other tokens. Each possible sequence has the same length, and simply
contains the raw digits of the addition problem.</p>
<p>As a few examples, the 2-digit problems:</p>
<ul>
<li>85 + 50 = 135 becomes the sequence [8, 5, 5, 0, 1, 3, 5]</li>
<li>6 + 39 = 45 becomes the sequence [0, 6, 3, 9, 0, 4, 5]
etc.</li>
</ul>
<p>We will also only train GPT on the final (n+1)-digits because the first
two n-digits are always assumed to be given. So when we give GPT an exam later,
we will e.g. feed it the sequence [0, 6, 3, 9], which encodes that we'd like
to add 6 + 39, and hope that the model completes the integer sequence with [0, 4, 5] in 3 sequential steps.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="k">class</span> <span class="nc">AdditionDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
  
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Our Custom Dataset Class for Generating Data into Training and Test sets.</span>
<span class="sd">    Returns addition problems of up to some number of digits in the inputs. We recall</span>
<span class="sd">    that all GPT cares about are sequences of integers, and completing them according to</span>
<span class="sd">    patterns in the data. Therefore, we have to somehow encode addition problems</span>
<span class="sd">    as a sequence of integers.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ndigit</span><span class="p">,</span> <span class="n">split</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">split</span> <span class="c1"># train/test</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ndigit</span> <span class="o">=</span> <span class="n">ndigit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># 10 possible digits 0..9</span>
        <span class="c1">#+1 due to potential carry overflow, but then -1 because very last digit doesn&#39;t plug back</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">ndigit</span> <span class="o">+</span> <span class="n">ndigit</span> <span class="o">+</span> <span class="n">ndigit</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span>
        
        <span class="c1">#split up all addition problems into either training data or test data : </span>
        <span class="n">num</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">ndigit</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="c1"># total number of possible combinations, here num = 10000</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1337</span><span class="p">)</span> <span class="c1"># making our datasets deterministic</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">num</span><span class="p">)</span> <span class="c1">#perm is an array of indexes</span>
        <span class="n">num_test</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num</span><span class="o">*</span><span class="mf">0.2</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span><span class="c1"># 20% of the whole dataset, or only up to 1000</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ixes</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[:</span><span class="n">num_test</span><span class="p">]</span> <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;test&#39;</span> <span class="k">else</span> <span class="n">perm</span><span class="p">[</span><span class="n">num_test</span><span class="p">:]</span> <span class="c1"># Here, We have taken 1000 examples in test set and 9000 in training set</span>

    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ixes</span><span class="o">.</span><span class="n">size</span> <span class="c1"># Magic method for using len(...)</span>


    <span class="c1"># Defining Magic Method __getitem__ for to use Dataset Class object as an iterable container.</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1"># given a problem index idx, first recover the associated a + b</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ixes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">nd</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">ndigit</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">//</span> <span class="n">nd</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">%</span>  <span class="n">nd</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
        <span class="n">render</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;%0</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndigit</span><span class="si">}</span><span class="s1">d%0</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndigit</span><span class="si">}</span><span class="s1">d%0</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndigit</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">d&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">)</span> <span class="c1"># e.g. 03+25=28 becomes &quot;0325028&quot; </span>
        <span class="n">dix</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">render</span><span class="p">]</span> <span class="c1"># convert each character to its token index</span>
        <span class="c1"># x will be input to GPT and y will be the associated expected outputs</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dix</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">dix</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span> <span class="c1"># predict the next token in the sequence</span>
        <span class="n">y</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">ndigit</span><span class="o">*</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span> <span class="c1"># we will only train in the output locations. -100 will mask loss to zero</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Creating our Training and Test Datasets for 2-Digit Addition</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ndigit</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">AdditionDataset</span><span class="p">(</span><span class="n">ndigit</span><span class="o">=</span><span class="n">ndigit</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">AdditionDataset</span><span class="p">(</span><span class="n">ndigit</span><span class="o">=</span><span class="n">ndigit</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sample a training instance just to see what one raw example looks like</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([4, 7, 1, 7, 0, 6]), tensor([-100, -100, -100,    0,    6,    4]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-Defining-our-GPT-Model">4. Defining our GPT Model<a class="anchor-link" href="#4.-Defining-our-GPT-Model"> </a></h2><ul>
<li>The initial stem consists of a combination of token encoding and a positional encoding</li>
<li><p>The Core of our model is a uniform sequence of Transformer blocks :</p>
<ul>
<li>each Transformer is a sequential combination of a 1-hidden-layer MLP block and a self-attention block</li>
<li>all blocks feed into a central residual pathway similar to resnets</li>
</ul>
</li>
<li><p>The final decoder is a linear projection into a vanilla Softmax classifier</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.1-Our-basic-config-classes-for-GPT-MODEL">4.1 Our basic config classes for GPT MODEL<a class="anchor-link" href="#4.1-Our-basic-config-classes-for-GPT-MODEL"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">GPTConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot; base GPT config, params common to all GPT versions &quot;&quot;&quot;</span>
    <span class="n">embd_pdrop</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">resid_pdrop</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">attn_pdrop</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">block_size</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">GPT1Config</span><span class="p">(</span><span class="n">GPTConfig</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; GPT-1 like network roughly 125M params &quot;&quot;&quot;</span>
    <span class="n">n_layer</span> <span class="o">=</span> <span class="mi">12</span>
    <span class="n">n_head</span> <span class="o">=</span> <span class="mi">12</span>
    <span class="n">n_embd</span> <span class="o">=</span> <span class="mi">768</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.2-Implementing-Self-Attention-Class-from-Scratch">4.2 Implementing Self-Attention Class from Scratch<a class="anchor-link" href="#4.2-Implementing-Self-Attention-Class-from-Scratch"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0167639320302806-gr2.jpg" alt="MHA" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, We will write our own class of Masked-MuliHead-Self Attention Block from scratch. Multi Head attention is perhaps one of the most important module of the transformer architecture. In case of transformers - they use a mechanism called self-attention instead of simple attention. Difference between simple attention and self-attention is that  - simple attention selectively focuses more on words which are present in query but in self-attention relationship with other surrounding(less-important) words is also taken into account to get a deep understanding of the context. In our model case of GPT , we have particularly used masked self attention which just means that, words to the right are no taken into account</p>
<ol>
<li>First our inputs of size (B,T,C) viz.( Mini-Batch Size, Embedding Size, ) is fed to the model. </li>
<li>There are 3 Linear Layers to which our inputs are fed which then output Queries, Keys, and Values of dim (Inp_vector,T).</li>
<li>Then we do (Queries@(keys).T)/sqrt(Embedding_Size) as our next step in order to calculate the attention score matrix.</li>
<li>We then apply masking matrix to this matrix, to convert it to lower diagonal matrix for making our attention to the left words only in future.</li>
<li>This matrix is then passed to softmax function which nornmalized all attention scores and also converts entries in the upper triangular half of -inf (in our case we have taken -100) to 0.</li>
<li>We further do a dropout layer for regularization (with p_atten_drop = 0.1) and then finally we do a matmul with the original value matrix of dim -&gt; (input_dim, embedding_size)</li>
<li>We then project our output to the same dimension as that of input by passing it to a linear layer to again get an output of size(B,T,C) so that further we can concatenate it with the ouputs of the other heads along the outermost dimension.</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">CausalSelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A vanilla multi-head masked self-attention layer with a projection at the end.</span>
<span class="sd">    It is also possible to use torch.nn.MultiheadAttention here.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">n_head</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="c1"># key, query, value projections for all heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="c1"># regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">attn_pdrop</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resid_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">resid_pdrop</span><span class="p">)</span>
        <span class="c1"># output projection</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="c1"># causal mask to ensure that attention is only applied to the left in the input sequence</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;mask&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">))</span>
                                     <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">n_head</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">layer_past</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="c1">#B-&gt;Batch Size, T-&gt;#Training rows, C-&gt;#Columns</span>

        <span class="c1"># calculate query, key, values for all heads in batch and move head forward to be the batch dim where hs = C//self.n_head</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span><span class="p">,</span> <span class="n">C</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># (B, nh, T, hs)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span><span class="p">,</span> <span class="n">C</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># (B, nh, T, hs)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span><span class="p">,</span> <span class="n">C</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_head</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># (B, nh, T, hs)</span>

        <span class="c1"># causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -&gt; (B, nh, T, T)</span>
        <span class="n">att</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span> <span class="o">@</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[:,:,:</span><span class="n">T</span><span class="p">,:</span><span class="n">T</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">))</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">att</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">att</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="p">(</span><span class="n">att</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">att</span> <span class="o">@</span> <span class="n">v</span> <span class="c1"># (B, nh, T, T) x (B, nh, T, hs) -&gt; (B, nh, T, hs)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span> <span class="c1"># re-assemble all head outputs side by side</span>

        <span class="c1"># output projection</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resid_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.3-Our-Basic-Transformer-Block">4.3 Our Basic Transformer Block<a class="anchor-link" href="#4.3-Our-Basic-Transformer-Block"> </a></h3><p>Here, we have defined a basic block which uses a config as an input (config is an instance of our GPTConfig Class) and defines the structure of a basic transformer block which will be used in future.</p>
<ul>
<li><a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">LayerNorm</a> is an linear layer normalization class inside Pytorch nn.Module used to apply Layer Normalization over a mini-batch of inputs.</li>
</ul>
<ol>
<li><p>First we apply a layer norm to a batch of inputs, which we pass on to the masked self-attention block and then add the input x again to the residual of the self attention block in order to capture original information again after the self-attention block. -&gt; x1</p>
</li>
<li><p>After that, we again pass that to a Normalizatoin layer, which we pass to a multilayered feed forward network with Linear-&gt;Gelu-&gt;Linear-&gt;Drouput layers to which we add input x1 of the above step 1.</p>
</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; our basic Transformer block &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">CausalSelfAttention</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">resid_pdrop</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.4-Full-GPT-Model-Class:">4.4 Full GPT Model Class:<a class="anchor-link" href="#4.4-Full-GPT-Model-Class:"> </a></h3><p>This is our main GPT model class for which we have defined our components as small blocks stated in various small classed explained above.</p>
<ol>
<li>This class also takes input config which is an instance of GPTConfig Class.</li>
<li>The functionalyti of each function which we use is expalined within the function body itself. (Pls. refer there for details).</li>
<li>For the forward function of this class, we take an input as the single row i.e one training row from our instance of AdditionDataset class.</li>
<li>#b=no. of examples in minibatch, t = #tokens in an example (maximum value of t = 6). our minibatch matrix of size (b,t).</li>
<li><p>Our token embedding layer and pos_embedding layer are defined as :
<code>&gt; self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)</code> &lt;/br&gt;
<code>&gt; self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))</code>
Our inputs are passed to these layers and then outputs of these layers are added as together so as to capture the positional information (which is a must required information in case of transformars model as compared to RNN/LSTM models which are already sequential).</p>
</li>
<li><p>Now we will just calculate and return the logits (probability function) of each of the digits in our vocab_size of 10 along with the loss (which we calculate only if the targets (y's) are provided initially).</p>
</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">GPT</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; This is our the full GPT language model, with a context size of block_size &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># input embedding stem</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">embd_pdrop</span><span class="p">)</span>
        <span class="c1"># transformer      </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">Block</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_layer</span><span class="p">)])</span>
        <span class="c1"># decoder head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">block_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_weights</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;number of parameters: </span><span class="si">%e</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">get_block_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span>

    <span class="k">def</span> <span class="nf">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>


  
    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_config</span><span class="p">):</span>


      <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      By this function, We are separating out all parameters of the model into two buckets: </span>
<span class="sd">      those that will experience weight decay for regularization and those that won&#39;t (biases, and layernorm/embedding weights).</span>
<span class="sd">      We are then returning the PyTorch optimizer object.</span>

<span class="sd">      &quot;&quot;&quot;</span>
      <span class="c1"># separate out all parameters to those that will and won&#39;t experience regularizing weight decay</span>
      <span class="n">decay</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
      <span class="n">no_decay</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
      <span class="n">whitelist_weight_modules</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="p">)</span>
      <span class="n">blacklist_weight_modules</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">mn</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
          <span class="k">for</span> <span class="n">pn</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
              <span class="n">fpn</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mn</span><span class="p">,</span> <span class="n">pn</span><span class="p">)</span> <span class="k">if</span> <span class="n">mn</span> <span class="k">else</span> <span class="n">pn</span> <span class="c1"># full param name</span>

              <span class="k">if</span> <span class="n">pn</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;bias&#39;</span><span class="p">):</span>
                  <span class="c1"># all biases will not be decayed</span>
                  <span class="n">no_decay</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">fpn</span><span class="p">)</span>
              <span class="k">elif</span> <span class="n">pn</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">whitelist_weight_modules</span><span class="p">):</span>
                  <span class="c1"># weights of whitelist modules will be weight decayed</span>
                  <span class="n">decay</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">fpn</span><span class="p">)</span>
              <span class="k">elif</span> <span class="n">pn</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">blacklist_weight_modules</span><span class="p">):</span>
                  <span class="c1"># weights of blacklist modules will NOT be weight decayed</span>
                  <span class="n">no_decay</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">fpn</span><span class="p">)</span>

      <span class="c1"># special case the position embedding parameter in the root GPT module as not decayed</span>
      <span class="n">no_decay</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s1">&#39;pos_emb&#39;</span><span class="p">)</span>

      <span class="c1"># validate that we considered every parameter</span>
      <span class="n">param_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">pn</span><span class="p">:</span> <span class="n">p</span> <span class="k">for</span> <span class="n">pn</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()}</span>
      <span class="n">inter_params</span> <span class="o">=</span> <span class="n">decay</span> <span class="o">&amp;</span> <span class="n">no_decay</span>
      <span class="n">union_params</span> <span class="o">=</span> <span class="n">decay</span> <span class="o">|</span> <span class="n">no_decay</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">inter_params</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;parameters </span><span class="si">%s</span><span class="s2"> made it into both decay/no_decay sets!&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">inter_params</span><span class="p">),</span> <span class="p">)</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">-</span> <span class="n">union_params</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;parameters </span><span class="si">%s</span><span class="s2"> were not separated into either decay/no_decay set!&quot;</span> \
                                                <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">param_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">-</span> <span class="n">union_params</span><span class="p">),</span> <span class="p">)</span>

      <span class="c1"># create the pytorch optimizer object</span>
      <span class="n">optim_groups</span> <span class="o">=</span> <span class="p">[</span>
          <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">param_dict</span><span class="p">[</span><span class="n">pn</span><span class="p">]</span> <span class="k">for</span> <span class="n">pn</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">decay</span><span class="p">))],</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">train_config</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">},</span>
          <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">param_dict</span><span class="p">[</span><span class="n">pn</span><span class="p">]</span> <span class="k">for</span> <span class="n">pn</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">no_decay</span><span class="p">))],</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
      <span class="p">]</span>
      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">optim_groups</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">train_config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">train_config</span><span class="o">.</span><span class="n">betas</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">optimizer</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">t</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;Cannot forward, model block size is exhausted.&quot;</span>

        <span class="c1"># forward the GPT model</span>
        <span class="n">token_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tok_emb</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="c1"># each index maps to a (learnable) vector</span>
        <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_emb</span><span class="p">[:,</span> <span class="p">:</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="c1"># each position maps to a (learnable) vector</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">token_embeddings</span> <span class="o">+</span> <span class="n">position_embeddings</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># if we are given some desired targets also calculate the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="We-can-now-initialize-our-GPT-Model-with-assumable-parameters-:">We can now initialize our GPT Model with assumable parameters :<a class="anchor-link" href="#We-can-now-initialize-our-GPT-Model-with-assumable-parameters-:"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">mconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">mconf</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="5.-Trainer-(Learner)-for-our-GPT-Model-:">5. Trainer (Learner) for our GPT Model :<a class="anchor-link" href="#5.-Trainer-(Learner)-for-our-GPT-Model-:"> </a></h2><p>Now we will define the trainer class of our model, to which we will  pass our defined instance of GPTModel along with some other tunable hyperparameters which are used in training in PyTorch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="5.1-Trainer-Config-Class">5.1 Trainer Config Class<a class="anchor-link" href="#5.1-Trainer-Config-Class"> </a></h3><p>Just like our GPT1Config and GPTCOnfig classes defined above, we have defined a seperate class for the main Traning class. It contains the hyperparameters which are used globally throughout in the main Trainer Class.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">TrainerConfig</span><span class="p">:</span>
    <span class="c1"># optimization parameters</span>
    <span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">3e-4</span>
    <span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span>
    <span class="n">grad_norm_clip</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># only applied on matmul weights</span>
    <span class="c1"># learning rate decay params: linear warmup followed by cosine decay to 10% of original</span>
    <span class="n">lr_decay</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">warmup_tokens</span> <span class="o">=</span> <span class="mf">375e6</span> <span class="c1"># these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere</span>
    <span class="n">final_tokens</span> <span class="o">=</span> <span class="mf">260e9</span> <span class="c1"># (at what point we reach 10% of original LR)</span>
    <span class="c1"># checkpoint settings</span>
    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># for DataLoader</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="5.2-Main-Trainer/Learner-Class">5.2 Main Trainer/Learner Class<a class="anchor-link" href="#5.2-Main-Trainer/Learner-Class"> </a></h3><p>This is the main class used for our GPT Model Training, it contains the instances of GPT model , train_dataset, test_dataset, config classes as inputs.</p>
<p>The model training goes on this way :</p>
<ol>
<li>First we construct 2 seperate dataloaders from PyTorch Dataloader class by using train_dataset, test_dataset which basically offer the functionality to load the data in size of minibatches of (x,y) on to the cpu/gpu whichever device is available.</li>
<li>then we collect our logits,losses from the output of out GPT() model.</li>
<li>We then use PyTorch's autograd mechanasim in order to backprop and update the parameters.</li>
</ol>
<ul>
<li><code>model.zero_grad()</code> - sets gradients to zero so that they don't accumulate.</li>
<li><code>loss.backward()</code> -  does the backpropogation step.</li>
<li><code>optimizer.step()</code> - updates the parameters throughout our model.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="o">=</span> <span class="n">test_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

        <span class="c1"># take over whatever gpus are on the system</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># DataParallel wrappers keep raw model object in .module attribute</span>
        <span class="n">raw_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">module</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;module&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;saving </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">raw_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">ckpt_path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span>
        <span class="n">raw_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">module</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;module&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">model</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">raw_model</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span><span class="n">split</span><span class="p">):</span>
            <span class="n">is_train</span> <span class="o">=</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">is_train</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="k">if</span> <span class="n">is_train</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                <span class="n">num_workers</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_workers</span><span class="p">)</span>

            <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span> <span class="k">if</span> <span class="n">is_train</span> <span class="k">else</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">it</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>

                <span class="c1"># place data on the correct device</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># forward the model</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">is_train</span><span class="p">):</span>
                    <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># collapse all losses if they are scattered on multiple gpus</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
                    <span class="c1"># backprop and update the parameters</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">config</span><span class="o">.</span><span class="n">grad_norm_clip</span><span class="p">)</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                    <span class="c1"># decay the learning rate based on our progress</span>
                    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">lr_decay</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">tokens</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="c1"># number of tokens processed this step (i.e. label is not -100)</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokens</span> <span class="o">&lt;</span> <span class="n">config</span><span class="o">.</span><span class="n">warmup_tokens</span><span class="p">:</span>
                            <span class="c1"># linear warmup</span>
                            <span class="n">lr_mult</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">warmup_tokens</span><span class="p">))</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># cosine learning rate decay</span>
                            <span class="n">progress</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens</span> <span class="o">-</span> <span class="n">config</span><span class="o">.</span><span class="n">warmup_tokens</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">final_tokens</span> <span class="o">-</span> <span class="n">config</span><span class="o">.</span><span class="n">warmup_tokens</span><span class="p">))</span>
                            <span class="n">lr_mult</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">progress</span><span class="p">)))</span>
                        <span class="n">lr</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">lr_mult</span>
                        <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                            <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">lr</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span>

                    <span class="c1"># report progress</span>
                    <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> iter </span><span class="si">{</span><span class="n">it</span><span class="si">}</span><span class="s2">: train loss </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">. lr </span><span class="si">{</span><span class="n">lr</span><span class="si">:</span><span class="s2">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_train</span><span class="p">:</span>
                <span class="n">test_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">))</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;test loss: </span><span class="si">%f</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">test_loss</span>

        <span class="n">best_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokens</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># counter used for learning rate decay</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">):</span>

            <span class="n">run_epoch</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">test_loss</span> <span class="o">=</span> <span class="n">run_epoch</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>

            <span class="c1"># supports early stopping based on the test loss, or just save always if no test set is provided</span>
            <span class="n">good_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_dataset</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">test_loss</span> <span class="o">&lt;</span> <span class="n">best_loss</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">ckpt_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">good_model</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">test_loss</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="6.-Model-Training-:">6. Model Training :<a class="anchor-link" href="#6.-Model-Training-:"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="n">tconf</span> <span class="o">=</span> <span class="n">TrainerConfig</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">6e-4</span><span class="p">,</span>
                      <span class="n">lr_decay</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">warmup_tokens</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">final_tokens</span><span class="o">=</span><span class="mi">50</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">ndigit</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span>
                      <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">tconf</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
epoch 1 iter 17: train loss 1.74271. lr 5.994512e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 14.37it/s]
epoch 2 iter 17: train loss 1.51097. lr 5.977197e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.21it/s]
epoch 3 iter 17: train loss 1.32211. lr 5.948114e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.80it/s]
epoch 4 iter 17: train loss 1.19657. lr 5.907379e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.51it/s]
epoch 5 iter 17: train loss 1.14752. lr 5.855153e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.75it/s]
epoch 6 iter 17: train loss 1.10465. lr 5.791641e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.21it/s]
epoch 7 iter 17: train loss 1.08063. lr 5.717095e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.92it/s]
epoch 8 iter 17: train loss 1.04661. lr 5.631810e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.82it/s]
epoch 9 iter 17: train loss 0.94335. lr 5.536122e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.41it/s]
epoch 10 iter 17: train loss 0.61353. lr 5.430411e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.91it/s]
epoch 11 iter 17: train loss 0.52056. lr 5.315093e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.92it/s]
epoch 12 iter 17: train loss 0.45946. lr 5.190624e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.11it/s]
epoch 13 iter 17: train loss 0.41773. lr 5.057497e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.13it/s]
epoch 14 iter 17: train loss 0.34299. lr 4.916238e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.04it/s]
epoch 15 iter 17: train loss 0.30794. lr 4.767405e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.23it/s]
epoch 16 iter 17: train loss 0.29624. lr 4.611586e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.71it/s]
epoch 17 iter 17: train loss 0.26151. lr 4.449397e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.74it/s]
epoch 18 iter 17: train loss 0.22487. lr 4.281479e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.48it/s]
epoch 19 iter 17: train loss 0.20200. lr 4.108497e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.69it/s]
epoch 20 iter 17: train loss 0.16634. lr 3.931133e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.10it/s]
epoch 21 iter 17: train loss 0.17252. lr 3.750088e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.21it/s]
epoch 22 iter 17: train loss 0.15451. lr 3.566079e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.97it/s]
epoch 23 iter 17: train loss 0.14947. lr 3.379832e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.65it/s]
epoch 24 iter 17: train loss 0.12629. lr 3.192084e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.56it/s]
epoch 25 iter 17: train loss 0.11772. lr 3.003577e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.39it/s]
epoch 26 iter 17: train loss 0.11381. lr 2.815056e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.44it/s]
epoch 27 iter 17: train loss 0.16899. lr 2.627266e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.43it/s]
epoch 28 iter 17: train loss 0.10231. lr 2.440948e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.49it/s]
epoch 29 iter 17: train loss 0.08752. lr 2.256841e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.43it/s]
epoch 30 iter 17: train loss 0.09948. lr 2.075671e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.13it/s]
epoch 31 iter 17: train loss 0.09623. lr 1.898155e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.16it/s]
epoch 32 iter 17: train loss 0.07943. lr 1.724993e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.79it/s]
epoch 33 iter 17: train loss 0.06771. lr 1.556871e-04: 100%|██████████| 18/18 [00:01&lt;00:00, 17.57it/s]
epoch 34 iter 17: train loss 0.06776. lr 1.394453e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 18.95it/s]
epoch 35 iter 17: train loss 0.07907. lr 1.238381e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.35it/s]
epoch 36 iter 17: train loss 0.07799. lr 1.089272e-04: 100%|██████████| 18/18 [00:00&lt;00:00, 19.50it/s]
epoch 37 iter 17: train loss 0.08679. lr 9.477150e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 19.37it/s]
epoch 38 iter 17: train loss 0.06168. lr 8.142699e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 18.58it/s]
epoch 39 iter 17: train loss 0.06297. lr 6.894639e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 18.86it/s]
epoch 40 iter 17: train loss 0.06865. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 18.81it/s]
epoch 41 iter 17: train loss 0.07373. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 19.54it/s]
epoch 42 iter 17: train loss 0.06541. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 19.05it/s]
epoch 43 iter 17: train loss 0.06758. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 19.30it/s]
epoch 44 iter 17: train loss 0.08270. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 19.62it/s]
epoch 45 iter 17: train loss 0.08476. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 19.03it/s]
epoch 46 iter 17: train loss 0.07492. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 18.81it/s]
epoch 47 iter 17: train loss 0.06154. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 18.13it/s]
epoch 48 iter 17: train loss 0.08624. lr 6.000000e-05: 100%|██████████| 18/18 [00:01&lt;00:00, 17.21it/s]
epoch 49 iter 17: train loss 0.07017. lr 6.000000e-05: 100%|██████████| 18/18 [00:00&lt;00:00, 18.23it/s]
epoch 50 iter 17: train loss 0.04833. lr 6.000000e-05: 100%|██████████| 18/18 [00:01&lt;00:00, 17.67it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="7.-Getting-Accuracy-on-Training-and-Validation-DataSets-:">7. Getting Accuracy on Training and Validation DataSets :<a class="anchor-link" href="#7.-Getting-Accuracy-on-Training-and-Validation-DataSets-:"> </a></h2><p>Now we will evaluate our miniature version of the transformer GPT model trained on our custom dataset (9000-&gt;training set size), (1000-&gt;validation set size) by providing it with an exam of doing Addition. Here, we also define our basic utilitiy functions which are used for sampling and doing inference on our training and validatoin sets.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Taking Top-k Logits  </span>
<span class="k">def</span> <span class="nf">top_k_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">v</span><span class="p">,</span> <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">out</span><span class="p">[</span><span class="n">out</span> <span class="o">&lt;</span> <span class="n">v</span><span class="p">[:,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]]</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;Inf&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function takes a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in</span>
<span class="sd">    the sequence, feeding the predictions back into the model each time. </span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">block_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_block_size</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
        <span class="n">x_cond</span> <span class="o">=</span> <span class="n">x</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">block_size</span> <span class="k">else</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="n">block_size</span><span class="p">:]</span> <span class="c1"># crop context if needed</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_cond</span><span class="p">)</span>
        <span class="c1"># pluck the logits at the final step and scale by temperature</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">/</span> <span class="n">temperature</span>
        <span class="c1"># optionally crop probabilities to only the top k options</span>
        <span class="k">if</span> <span class="n">top_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">top_k_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">top_k</span><span class="p">)</span>
        <span class="c1"># apply softmax to convert to probabilities</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># sample from the distribution or take the most likely</span>
        <span class="k">if</span> <span class="n">sample</span><span class="p">:</span>
            <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># append to the sequence and continue</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">ix</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data.dataloader</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="k">def</span> <span class="nf">give_exam</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_batches</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>    
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">d1d2</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ndigit</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">d1d2d3</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">d1d2</span><span class="p">,</span> <span class="n">ndigit</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">d3</span> <span class="o">=</span> <span class="n">d1d2d3</span><span class="p">[:,</span> <span class="o">-</span><span class="p">(</span><span class="n">ndigit</span><span class="o">+</span><span class="mi">1</span><span class="p">):]</span>
        <span class="n">factors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">10</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndigit</span><span class="o">+</span><span class="mi">1</span><span class="p">)][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># decode the integers from individual digits</span>
        <span class="n">d1i</span> <span class="o">=</span> <span class="p">(</span><span class="n">d1d2</span><span class="p">[:,:</span><span class="n">ndigit</span><span class="p">]</span> <span class="o">*</span> <span class="n">factors</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">d2i</span> <span class="o">=</span> <span class="p">(</span><span class="n">d1d2</span><span class="p">[:,</span><span class="n">ndigit</span><span class="p">:</span><span class="n">ndigit</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">factors</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">d3i_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">d3</span> <span class="o">*</span> <span class="n">factors</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">d3i_gt</span> <span class="o">=</span> <span class="n">d1i</span> <span class="o">+</span> <span class="n">d2i</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">d3i_pred</span> <span class="o">==</span> <span class="n">d3i_gt</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="c1"># Software 1.0 vs. Software 2.0 fight RIGHT on this line, lol</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="n">judge</span> <span class="o">=</span> <span class="s1">&#39;YEP!!!&#39;</span> <span class="k">if</span> <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;NOPE&#39;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPT claims that </span><span class="si">%03d</span><span class="s2"> + </span><span class="si">%03d</span><span class="s2"> = </span><span class="si">%03d</span><span class="s2"> (gt is </span><span class="si">%03d</span><span class="s2">; </span><span class="si">%s</span><span class="s2">)&quot;</span> 
                      <span class="o">%</span> <span class="p">(</span><span class="n">d1i</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">d2i</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">d3i_pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">d3i_gt</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">judge</span><span class="p">))</span>
        
        <span class="k">if</span> <span class="n">max_batches</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">b</span><span class="o">+</span><span class="mi">1</span> <span class="o">&gt;=</span> <span class="n">max_batches</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;final score: </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2"> = </span><span class="si">%.2f%%</span><span class="s2"> correct&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">give_exam</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">max_batches</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>GPT claims that 045 + 055 = 090 (gt is 100; NOPE)
final score: 8999/9000 = 99.99% correct
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">give_exam</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">max_batches</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>GPT claims that 055 + 045 = 090 (gt is 100; NOPE)
final score: 999/1000 = 99.90% correct
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="Geek4ray/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/gpt/transformers/2021/11/22/Implementing-Miniature-GPT-Model.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/Geek4ray" title="Geek4ray"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/KejriwalRayan" title="KejriwalRayan"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
