{
  
    
        "post0": {
            "title": "Tesla AI Day",
            "content": ". Raw inputs which come into the stack and neural net processes into a vector space .",
            "url": "https://geek4ray.github.io/blog/fastpages/jupyter/2021/09/18/_09_19_Tesla_AI_Day.html",
            "relUrl": "/fastpages/jupyter/2021/09/18/_09_19_Tesla_AI_Day.html",
            "date": " • Sep 18, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "My Resume",
            "content": "Rayan Kejriwal . +91-94618 73955 | Bhiwadi, Rajasthan, India, 301019 | . aryankejriwal4@gmail.com | https://geek4ray.github.io/blog/ | linkedin.com/in/rayan-kejriwal/ | . **Data Science | Machine Learning | Quantitative Finance | Mathematics** | . Data Science Enthusiast actively following AI research community and seeking for automation in the real- world. Always willing to live in a competitive environment, meeting people and exploring new technologies leveraging the power of AI. . EDUCATION . B.Tech. Electronics and Communication 07/2018 – Present . Indian Institute of Information Technology, Allahabad CGPA - 8.19/10 . Senior Secondary 04/2017 – 04/2018 . Prince International School, Jaipur CBSE - 87.4% . Secondary 04/2015 – 04/2016 . Modern Public School, Bhiwadi CBSE – 10/10 . Technical Skills . Languages: C++, Python, SQL . | Frameworks: PyTorch, Fastai . | Tools/Software: Jupyter, VBA Excel, MATLAB . | Libraries: Numpy, Pandas, Scikit, Matplotlib, Seaborn . | . | Key Skills . Machine Learning | Neural Nets | EDA | Deep Reinforcement Learning | Numerical Methods | . Object-Oriented Programming | Probability | . Statistics | Quantitative Analysis | . Hypotheses Testing | Timeseries . | . SKILLS . PROJECTS . Numerai 07/2021 – Present . Open-Source Hedge Fund . Known as the hardest data science tournament on the planet . | Stock Data Modeling . | . Human Activity Recognition System 04/2021 – 05/2021 . B.Tech. Mini Project . Activity Classification based on Real-time Data from MPU-6050 sensor fitted on a Wearable Band . | Feature Engineered 140 Predictive Variables . | . Kaggle Competitions 12/2020 – Present . Coleridge Initiative . Entity Extraction using Transformers API. | . Jane Street Market Prediction . Binary Classification, Financial Timeseries Modeling using Neural Network. . | Processing with NVTabular + Rapids API along with Dask Framework including floating-point precision and Numba Speedup. | . Other Major Works 06/2020 – 04/2021 . Quant . Implemented Greeks (using FDM), Jump Diffusion Model, Implied Volatility Model, and European Vanilla option payoff using Black Scholes, Monte Carlo and Asian Discrete Path dependent formula. Currently Studying Financial applications using Reinforcement Learning. . | Used generic programming and functors in C++. . | Other supporting numerical method implementations include Decomposition methods – LU, Cholesky, QR and Thomas Algorithm using Eigen Library. . | . Multilabel Face Classification: CelebA Dataset . To characterize Celebrity faces with multi-label face attributes, used Fastai Data Block API, transfer learning using Resnet-50, and fine-tuning to achieve an accuracy of 92% . | Deployed the web app using Jupyter Widgets and Voila . | . Image Segmentation: Camvid Dataset . Pixel wise Segmentation of image using Dynamic U-NET, also implemented from scratch. . | Further improved the model by using novel approaches like image resizing, ranger optimizer, fit-flat cos, and Mish activation. Achieved state-of-the-art. . | . Price Prediction: Blue Book for Bulldozers . Predicting Auction Sale Prices of heavy automobile equipment used Random Forest also implemented Random forest Regressor from scratch. . | Model Interpretation using RF feature importance, Tree Interpreter, Partial Dependence Plot (waterfall), and Tree Variance. . | . Other Datasets Worked . Rossman, Oxford Pet, Biwi Head Pose, RedWine, Adult, MNIST, CIFAR, IMDB, House Prediction, and Titanic | . RESPONSIBILITIES . IIITA Info Communication and Incubation Centre 08/2018 – 06/2021 . Overall Coordinator . Invited Global AI Leaders from FAIR, Microsoft, IBM, NUS, U of T, and Harvard at E-Summit’21 conference sponsored by Walmart and Cisco, lead a team of 89 People; conducted 3 successful editions of E-Summit so far. (2018-2021) . | Lead Organizer of B-Hacks’20. (2020) . | Campus Director of Global Hult Prize, IIIT Allahabad Chapter for the first time. (2020) . | Visited 25+ Coworking spaces in Delhi-NCR to collaborate with start-ups sponsored by NewGen IEDC (2018) . | . HONORS . GATE Statistics: AIR-127 (2021) . | Dronathon 2019: Overall Winner (2019) . | 1st North India Open Karate Championship: Bronze (2012), Silver (2013) . | . INTERESTS . Martial Arts (Karate), Yoga and Meditation, Casual Music (Synth and Vocals). | .",
            "url": "https://geek4ray.github.io/blog/2021/09/18/My-Resume.html",
            "relUrl": "/2021/09/18/My-Resume.html",
            "date": " • Sep 18, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Introducing fastpages",
            "content": ". We are very pleased to announce the immediate availability of fastpages. fastpages is a platform which allows you to create and host a blog for free, with no ads and many useful features, such as: . Create posts containing code, outputs of code (which can be interactive), formatted text, etc directly from Jupyter Notebooks; for instance see this great example post from Scott Hawley. Notebook posts support features such as: Interactive visualizations made with Altair remain interactive. | Hide or show cell input and output. | Collapsable code cells that are either open or closed by default. | Define the Title, Summary and other metadata via a special markdown cells | Ability to add links to Colab and GitHub automatically. | . | Create posts, including formatting and images, directly from Microsoft Word documents. | Create and edit Markdown posts entirely online using GitHub&#39;s built-in markdown editor. | Embed Twitter cards and YouTube videos. | Categorization of blog posts by user-supplied tags for discoverability. | ... and much more | . fastpages relies on Github pages for hosting, and Github Actions to automate the creation of your blog. The setup takes around three minutes, and does not require any technical knowledge or expertise. Due to built-in automation of fastpages, you don&#39;t have to fuss with conversion scripts. All you have to do is save your Jupyter notebook, Word document or markdown file into a specified directory and the rest happens automatically. Infact, this blog post is written in a Jupyter notebook, which you can see with the &quot;View on GitHub&quot; link above. . fast.ai have previously released a similar project called fast_template, which is even easier to set up, but does not support automatic creation of posts from Microsoft Word or Jupyter notebooks, including many of the features outlined above. . Because fastpages is more flexible and extensible, we recommend using it where possible. fast_template may be a better option for getting folks blogging who have no technical expertise at all, and will only be creating posts using Github&#39;s integrated online editor. . Setting Up Fastpages . The setup process of fastpages is automated with GitHub Actions, too! Upon creating a repo from the fastpages template, a pull request will automatically be opened (after ~ 30 seconds) configuring your blog so it can start working. The automated pull request will greet you with instructions like this: . . All you have to do is follow these instructions (in the PR you receive) and your new blogging site will be up and running! . Jupyter Notebooks &amp; Fastpages . In this post, we will cover special features that fastpages provides for Jupyter notebooks. You can also write your blog posts with Word documents or markdown in fastpages, which contain many, but not all the same features. . Options via FrontMatter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . All of the above settings are enabled in this post, so you can see what they look like! . the summary field (preceeded by &gt;) will be displayed under your title, and will also be used by social media to display as the description of your page. | toc: setting this to true will automatically generate a table of contents | badges: setting this to true will display Google Colab and GitHub links on your blog post. | comments: setting this to true will enable comments. See these instructions for more details. | author this will display the authors names. | categories will allow your post to be categorized on a &quot;Tags&quot; page, where readers can browse your post by categories. | . Markdown front matter is formatted similarly to notebooks. The differences between the two can be viewed on the fastpages README. . Code Folding . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . If you want to completely hide cells (not just collapse them), read these instructions. . Interactive Charts With Altair . Interactive visualizations made with Altair remain interactive! . We leave this below cell unhidden so you can enjoy a preview of syntax highlighting in fastpages, which uses the Dracula theme. . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;IMDB_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget IMDB_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | 6.1 | . 1 First Love, Last Rites | 10876.0 | 300000.0 | 6.9 | . 2 I Married a Strange Person | 203134.0 | 250000.0 | 6.8 | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | NaN | . 4 Slam | 1087521.0 | 1000000.0 | 3.4 | . Other Features . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Images w/Captions . You can include markdown images with captions like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Of course, the caption is optional. . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . More Examples . This tutorial contains more examples of what you can do with notebooks. . How fastpages Converts Notebooks to Blog Posts . fastpages uses nbdev to power the conversion process of Jupyter Notebooks to blog posts. When you save a notebook into the /_notebooks folder of your repository, GitHub Actions applies nbdev against those notebooks automatically. The same process occurs when you save Word documents or markdown files into the _word or _posts directory, respectively. . We will discuss how GitHub Actions work in a follow up blog post. . Resources &amp; Next Steps . We highly encourage you to start blogging with fastpages! Some resources that may be helpful: . fastpages repo - this is where you can go to create your own fastpages blog! | Fastai forums - nbdev &amp; blogging category. You can ask questions about fastpages here, as well as suggest new features. | nbdev: this project powers the conversion of Jupyter notebooks to blog posts. | . If you end up writing a blog post using fastpages, please let us know on Twitter: @jeremyphoward, @HamelHusain. .",
            "url": "https://geek4ray.github.io/blog/fastpages/jupyter/2021/09/02/introducing-fastpages.html",
            "relUrl": "/fastpages/jupyter/2021/09/02/introducing-fastpages.html",
            "date": " • Sep 2, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Building Complex AI Algorithms from scratch",
            "content": "Lets talk about basic SGD in Pytorch . def f(x): return x**2 . xt = tensor(3.).requires_grad_() . Notice the special method requires_grad_? That&#39;s the magical incantation we use to tell PyTorch that we want to calculate gradients with respect to that variable at that value. It is essentially tagging the variable, so PyTorch will remember to keep track of how to compute gradients of the other, direct calculations on it that you will ask for. . yt = f(xt) . yt.backward() . The &quot;backward&quot; here refers to backpropagation, which is the name given to the process of calculating the derivative of each layer (in case of neural network). . xt.grad #(This grad arrtibute accumulates the gradient at the variable x and keeps adding them consecutively unless you zero out the recent grads by using **zero_grad** arrtibute. . tensor(6.) . xt.grad.zero_() . tensor(0.) . Now we can try with a vector : . def f(x): return (x**2).sum() . def calc_grad(x,f): y=f(x) y.backward() print(x.grad) x.grad.zero_() . calc_grad(tensor([3.,4.,5.],requires_grad=True),f) . tensor([ 6., 8., 10.]) . As we can see, we got right results! One thing is to notice that tensors always accept floating points and the grad can be implicitly created only for scalar outputs therefore the function f must return a scalar thats why we did apply .sum(). . Lets Take Another End-To-End Example of SGD . time = torch.arange(20).float() time . speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1 plt.scatter(time,speed); . def f(t, params): a,b,c=params return a*(t**2) + b*t + c . params = torch.randn(3).requires_grad_() orig_params = params.clone() # Clone method will also copy autograd func. orig_params . tensor([0.2193, 0.4842, 0.5411], grad_fn=&lt;CloneBackward&gt;) . preds = f(time, params) . Let&#39;s create a little function to see how close our predictions are to our targets, and take a look: . def show_preds(preds, ax=None): if ax is None: ax=plt.subplots()[1] ax.scatter(time, speed) ax.scatter(time, (preds).detach().numpy(), color=&#39;red&#39;) ax.set_ylim(-300,100) . show_preds(preds) . loss = F.mse_loss(preds,speed) loss . tensor(1017.8171, grad_fn=&lt;MseLossBackward&gt;) . Our Goal is to now improve this loss. The next step is to calculate the gradients. . loss.backward() # .backward() method is applied on the variable of which we want to calculate gradient. params.grad # gradient is calculated w.r.t params -&gt;(a,b,c) . tensor([6582.9756, 437.4914, 13.7502]) . lr = 1e-5 params.grad * lr . tensor([0.0658, 0.0044, 0.0001]) . params.data -= params.grad.data*lr . params.grad = None . Understanding this bit depends on remembering recent history. To calculate the gradients we call backward on the loss. But this loss was itself calculated by mse, which in turn took preds as an input, which was calculated using f taking as an input params, which was the object on which we originally called requiredgrads—which is the original call that now allows us to call backward on loss. This chain of function calls represents the mathematical composition of functions, which enables PyTorch to use calculus&#39;s chain rule under the hood to calculate these gradients. . preds = f(time,params) F.mse_loss(preds,speed) . tensor(705.5072, grad_fn=&lt;MseLossBackward&gt;) . show_preds(preds) . def apply_step(params,prn=True): preds = f(time,params) loss = F.mse_loss(preds,speed) loss.backward() params.data -= params.grad.data*1e-5 params.grad = None if prn: print(loss.item()) #In this case our Metric is same as loss function return preds . for i in range(10): apply_step(params) . 646.4049072265625 642.8947143554688 634.5457153320312 632.962158203125 632.65869140625 632.5977172851562 632.5823974609375 632.5758666992188 632.5709228515625 632.5662841796875 . We just decided to stop after 10 epochs arbitrarily. In practice, we would watch the training and validation losses and our metrics to decide when to stop . params = torch.randn(3).requires_grad_() _,axs = plt.subplots(1,8,figsize=(24,3)) for ax in axs: show_preds(apply_step(params, False), ax) plt.tight_layout() . In 8 epochs, from left to right we can see that how our predictions are improving with a constant lr=1e-5 . 2) A simple Logistic Regression Class . class LogisticRegression(): def __init__(self) : pass def get_params(self,size) -&gt; torch.LongTensor: return torch.randn(size).requires_grad_() def sigmoid(self,x) : return 1/(1+torch.exp(-x)) def mse_loss(self,predictions,targets) -&gt; torch.LongTensor: return torch.where(targets==1, 1-predictions, predictions).mean() def fit(self,x,y,epochs,bs,lr,trim=False): dset = list(zip(x,y)) n_batches = int(len(dset)/bs) if (trim==False) : n_mini_batches= n_batches+int(len(dset)%bs) weights = self.get_params(x.shape[1]) bias = self.get_params(1) for e in range(epochs): for i in range(n_mini_batches): if(i == n_mini_batches-1) : xb = x[i*bs:] else : xb = x[i*bs:(i+1)*bs] preds = self.sigmoid(x@weights + bias) loss = self.mse_loss(preds,y) loss.backward() weights.data -= weights.grad.data*lr bias.data -= bias.grad.data*lr weights.grad = None bias.grad = None print(f&quot;Epoch_{e}_accuracy = &quot;,((preds&gt;=0.5)==y).float().mean().item()) def predict(self,x): return x*weights + bias . 3) Experimenting with MNIST : . (path/&#39;train&#39;).ls() . (#2) [Path(&#39;train/3&#39;),Path(&#39;train/7&#39;)] . (path/&#39;valid&#39;).ls() . (#2) [Path(&#39;valid/3&#39;),Path(&#39;valid/7&#39;)] . train_x = torch.cat([train_3_tens, train_7_tens]).view(-1, 28*28) valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28) train_y = tensor([1]*len(train_3_tens) + [0]*len(train_7_tens)).unsqueeze(1) valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1) . train_x.shape, valid_x.shape . (torch.Size([12396, 784]), torch.Size([2038, 784])) . m = LogisticRegression() . m.fit(x=train_x,y=train_y,bs=100,lr=1e-5,epochs=10) . Epoch_0_accuracy = 0.5040026903152466 Epoch_1_accuracy = 0.5040026903152466 Epoch_2_accuracy = 0.5040026903152466 Epoch_3_accuracy = 0.5040026903152466 Epoch_4_accuracy = 0.5040026903152466 Epoch_5_accuracy = 0.5040026903152466 Epoch_6_accuracy = 0.5040026903152466 Epoch_7_accuracy = 0.5040026903152466 Epoch_8_accuracy = 0.5040026903152466 Epoch_9_accuracy = 0.5040026903152466 . Putting it Altogether - Using Fastai Dataloaders ! . train_dset = list(zip(train_x,train_y)) valid_dset = list(zip(valid_x,valid_y)) . . Note: Now we will use fastai Dataloaders for to Load Data in mini-batches rathar than a single row in SGD. Just To say * Dataset - A list of tuples each tuple of form -&gt; $(x_i,y_i)$ . DataLoader - An Iterable/List of Minibatches where each minibatch is of the form $tuple(tensor(x_1,x_2,...,x_b), (y_1,y_2,...,y_b))$. | .",
            "url": "https://geek4ray.github.io/blog/ai/algorithms/2021/09/02/AI_Algorithms.html",
            "relUrl": "/ai/algorithms/2021/09/02/AI_Algorithms.html",
            "date": " • Sep 2, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "My Name is Rayan Kejriwal, I am a currently a Final Year B.Tech. ECE undergraduate student at IIIT Allahabad, India. I am a Data Science Enthusiast and like to be a part of active AI research communities and seeking for automation in the real-world. I am always willing to live in a competitive environment, meeting people and exploring new technologies leveraging the power of AI. Also I am quite interested about Quantitative Finance and my current research interests include the applications of AI in Finance. . Contact me . aryankejriwal4@gmail.com .",
          "url": "https://geek4ray.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://geek4ray.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}